{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_json('preprints_prep.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7621, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate neuro data from the rest\n",
    "neuro_data = data[data['preprint_category']=='neuroscience']\n",
    "neuro_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set DOI (all lowercase) as index\n",
    "neuro_data = neuro_data.set_index(neuro_data.published_doi.str.lower())\n",
    "\n",
    "# add journal column\n",
    "neuro_data['journal'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding journal info per paper\n",
    "### Use crossref API to get journal info\n",
    "NB: Not all papers are registered with crossref, but it seems to be the vast majority\n",
    "\n",
    "Useful reference:https://github.com/CrossRef/rest-api-doc#filter-names\n",
    "\n",
    "1) Split data into sets of n_per_req (entries per request)\n",
    "\n",
    "2) send a query to crossref api. concatenate the DOIs of n_per_req papers. request the doi and container-title (journal name) in results\n",
    "\n",
    "3) match the container-titles returned to the DOI to fill in the journal column\n",
    "\n",
    "4) Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all DOIs in neuro_data, access journal information using the crossref API\n",
    "n_per_req = 100 # number of entries per request\n",
    "# initialize query\n",
    "query = {'filter':'doi:10.3389/fnsys.2016.00088',\n",
    "         'rows':n_per_req,\n",
    "         'select':'DOI,container-title',\n",
    "         'mailto':'m.frid@protonmail.com'}\n",
    "# loop through articles\n",
    "for x in np.arange(0,neuro_data.shape[0]+n_per_req,n_per_req): #\n",
    "    #build query string with dois of n_per_req papers\n",
    "    t = time.time()\n",
    "    doi_str = \"\"\n",
    "    for xx in np.arange(n_per_req):\n",
    "        if (x + xx) < neuro_data.shape[0]:\n",
    "            doi_str += \"doi:\" + neuro_data.published_doi.iloc[x+xx] + ','\n",
    "    doi_str = doi_str[:-1] # get rid of last comma\n",
    "    query['filter'] = doi_str\n",
    "    \n",
    "    #access crossref api\n",
    "    response = requests.get(crossref_url, params=query)\n",
    "    r = response.json()\n",
    "    print(f\"{x} of {neuro_data.shape[0]}. {time.time()-t}s elapsed for query. {r['message']['total-results']} results found\")\n",
    "    t = time.time()\n",
    "    for xx in np.arange(r['message']['total-results']):\n",
    "        ind = r['message']['items'][xx]['DOI']\n",
    "        neuro_data.loc[ind,'journal'] = r['message']['items'][xx]['container-title'][0]\n",
    "    print(f\"{time.time()-t}s elapsed for pandas bookkeepping\")  \n",
    "#save df\n",
    "neuro_data.to_csv('neuro_journals_doi_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative (original) way of ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use crossref api to get journal title from DOI\n",
    "# ****very slow bc it gets one entry per request****\n",
    "journals = neuro_data.published_doi.copy().rename_axis('journal_name')\n",
    "crossref_url = 'http://api.crossref.org/works' \n",
    "query = {'filter':'doi:10.3389/fnsys.2016.00088','rows':1,'select':'DOI,container-title','mailto':'m.frid@protonmail.com'}\n",
    "for x, doi in enumerate(neuro_data.published_doi.iteritems()):\n",
    "    print(str(x) + ' out of ' + str(journals.shape[0]) + ': ' + doi[1])\n",
    "    query['filter'] = 'doi:' + doi[1]\n",
    "    response = requests.get(crossref_url, params=query)\n",
    "    r = response.json()\n",
    "    if r['message']['total-results'] > 0:\n",
    "        journals[doi[0]] = r['message']['items'][0]['container-title'][0]\n",
    "    else:\n",
    "        journals[doi[0]] = ''\n",
    "\n",
    "pd.concat([journals,neuro_data.published_doi],axis=1).to_csv('neuro_journals_doi_2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
